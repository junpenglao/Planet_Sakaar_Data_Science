{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0827192-9773-4bf9-a334-21cb9844246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import aesara\n",
    "import aesara.tensor as at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8535ab42-3b81-4cb9-9383-a4884f6cf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_EXAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a3ad92-8319-49b7-998b-78ffe456bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(SIMPLE_EXAMPLE, x_obs=None):\n",
    "    if SIMPLE_EXAMPLE:\n",
    "        with pm.Model() as funnel:\n",
    "            θ = pm.Normal(\"θ\", 0, 3)\n",
    "            z = pm.Normal(\"z\", 0, at.exp(θ / 2), size=512)\n",
    "            x = pm.Normal(\"x\", z, 1, observed=x_obs)\n",
    "    else:\n",
    "        with pm.Model() as funnel:\n",
    "            θ0 = pm.Normal(\"θ0\", 0, 3)\n",
    "            z0 = pm.Normal(\"z0\", 0, at.exp(θ0 / 2), size=256)\n",
    "            θ1 = pm.HalfNormal(\"θ1\", 5)\n",
    "            z1 = pm.Normal(\"z1\", 0, θ1, size=(128, 2))\n",
    "            σ = pm.HalfNormal(\"σ\", 1)\n",
    "            x = pm.Normal(\"x\", at.stack([z0, at.flatten(z1)]), σ, observed=x_obs)\n",
    "    return funnel\n",
    "\n",
    "m = gen_model(SIMPLE_EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b4b49-7ac1-4b8d-a9a4-366d7a757286",
   "metadata": {},
   "source": [
    "Generate data for `x` condition on some true $\\theta$. There are a few ways to do it as explained in https://github.com/pymc-devs/pymc/discussions/5280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b9d481-9686-40cf-a79e-89f553f9fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SIMPLE_EXAMPLE:\n",
    "    sample_x: callable = aesara.function([m.θ], [m.x])\n",
    "    x_obs, = sample_x(1.)\n",
    "else:\n",
    "    sample_x: callable = aesara.function([m.θ0, m.θ1, m.σ], [m.x])\n",
    "    x_obs, = sample_x(0., 1., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6888bd47-1f2f-425c-a624-cb39f3542b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c3db7-b98e-44ab-86aa-2ddaf2d5953b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define a regular PyMC model that conditioned on some observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30396006-2eef-4a07-bb68-c9afe874dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "funnel = gen_model(SIMPLE_EXAMPLE, x_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cba126-7925-4fc4-9233-fed52a40db46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Forward sampling function (for generating `x`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d66aff-ab8d-4d2a-80a9-6fd700b22b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x_z = aesara.function([θ], [z, x])\n",
    "model_graph = pm.model_graph.ModelGraph(funnel)\n",
    "# theta are priors with no parent\n",
    "theta = [var for var in funnel.basic_RVs if model_graph.get_parent_names(var) == set()]\n",
    "# The remaining free variables are z\n",
    "latent_field = [var for var in funnel.free_RVs if var not in theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f7f413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z0', 'z1', 'σ'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph.get_parent_names(funnel.basic_RVs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16668ae9-2780-4056-a2c9-60a2fd2180ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[θ0, z0, θ1, z1, σ, x]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funnel.basic_RVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba28c640-df3b-46e2-8380-642c9909c50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([θ0, θ1, σ], [z0, z1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, latent_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522d51a7-fb65-42da-bc2f-160baa6aa89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 256), (256,), (128, 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z_x = list(set(funnel.value_vars) - set(theta))  # Not doing this as the order is unpredictable\n",
    "z_x: list = funnel.observed_RVs + latent_field\n",
    "\n",
    "sample_x_z: callable = aesara.function(theta, z_x)\n",
    "theta_val = [v.eval() for v in theta]\n",
    "output_test = sample_x_z(*theta_val)\n",
    "[v.shape for v in output_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f27cbd-4b01-4aab-a710-d0a0d1afa578",
   "metadata": {},
   "source": [
    "Alternative `sample_x` that only output the simulation of the observed (`x`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9015bf32-0266-48c1-a8fe-defd7f53a61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 256)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x: callable = aesara.function(theta, funnel.observed_RVs)\n",
    "theta_val = [v.eval() for v in theta]\n",
    "output_test = sample_x(*theta_val)\n",
    "[v.shape for v in output_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317540b-37e9-494c-90d1-2d019a23b2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Likelihood function `logP(x,z|θ)` and Prior function `logP(θ)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ba9032-9b44-4a5d-b8ee-53a636af06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc.distributions import joint_logpt\n",
    "\n",
    "# Copy and small modification of self.logp_elemwiset in a pm.Model\n",
    "def generate_logpt_allnodes(model, vars: list, jacobian: bool = True):\n",
    "    \"\"\"Elemwise log-probability of the input variables.\"\"\"\n",
    "    if model.potentials:\n",
    "        raise Exception(\"Does not work with model that contains potentials\")\n",
    "\n",
    "    rv_values = {}\n",
    "    for var in vars:\n",
    "        if var in model.observed_RVs:\n",
    "            value_var = var.type()\n",
    "            value_var.name = var.name\n",
    "        else:\n",
    "            value_var = model.rvs_to_values[var]\n",
    "        if value_var is not None:\n",
    "            rv_values[var] = value_var\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Requested variable {var} not found among the model variables\"\n",
    "            )\n",
    "\n",
    "    rv_logps = joint_logpt(list(rv_values.keys()), rv_values, sum=False, jacobian=jacobian)\n",
    "    logpt_nodes = {}\n",
    "    for k, logp in zip(rv_values.keys(), rv_logps):\n",
    "        node_logp = logp.sum()\n",
    "        node_logp.name = k.name + \"_logpt\"\n",
    "        logpt_nodes[k] = node_logp\n",
    "\n",
    "    return logpt_nodes, rv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b668e5c-e3c3-49c1-9682-0bec34a3ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the order of z, x, θ\n",
    "ordered_input_var: list = latent_field + funnel.observed_RVs + theta\n",
    "\n",
    "logpt_nodes, rv_values = generate_logpt_allnodes(funnel, ordered_input_var)\n",
    "input_var = [rv_values[v] for v in ordered_input_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4cf0351-24bb-4536-b142-4572fe79bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{z0: z0_logpt,\n",
       " z1: z1_logpt,\n",
       " x: x_logpt,\n",
       " θ0: θ0_logpt,\n",
       " θ1: θ1_logpt,\n",
       " σ: σ_logpt}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpt_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c7bbe8a-995f-4dd1-ba30-c01d0fba772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{z0: z0, z1: z1, x: x, θ0: θ0, θ1: θ1_log__, σ: σ_log__}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1536bf2f-1014-46df-965d-bb4d86fcf124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(-235.2482645), array(-647.26437008), array(-1648.90683217), array(-2.01755082), array(-0.72579135), array(-0.72579135)]\n",
      "[z0, z1, x, θ0, θ1, σ]\n",
      "\n",
      "From PyMC model itself\n",
      "{'θ0': -2.02, 'z0': -235.25, 'θ1': -0.73, 'z1': -647.26, 'σ': -0.73, 'x': -1648.91}\n"
     ]
    }
   ],
   "source": [
    "# Some testing\n",
    "compile_logp_fn_per_node = aesara.function(\n",
    "    input_var, [logpt_nodes[v] for v in ordered_input_var])\n",
    "test_point = funnel.initial_point()\n",
    "\n",
    "z_val = [test_point[rv_values[v].name] for v in latent_field]\n",
    "θ_val = [test_point[rv_values[v].name] for v in theta]\n",
    "\n",
    "x_val = [funnel.rvs_to_values[v].data for v in funnel.observed_RVs]\n",
    "\n",
    "print(compile_logp_fn_per_node(*z_val, *x_val, *θ_val))\n",
    "print(ordered_input_var)\n",
    "print(\"\\nFrom PyMC model itself\")\n",
    "print(funnel.point_logps(test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8669dade-0184-4edd-b9df-7cd8237e4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpt_z_x = []\n",
    "logpt_theta = []\n",
    "input_theta = []\n",
    "for var in ordered_input_var:\n",
    "    if var not in theta:\n",
    "        logpt_z_x.append(logpt_nodes[var])\n",
    "    else:\n",
    "        logpt_theta.append(logpt_nodes[var])\n",
    "        input_theta.append(rv_values[var])\n",
    "\n",
    "condition_logpt = at.sum(logpt_z_x)\n",
    "compile_logp_fn = aesara.function(input_var, [condition_logpt])\n",
    "theta_logpt = at.sum(logpt_theta)\n",
    "compile_logp_fn_theta = aesara.function(input_theta, [theta_logpt])\n",
    "\n",
    "# compare to full posterior as check\n",
    "np.testing.assert_almost_equal(sum(compile_logp_fn(*z_val, *x_val, *θ_val) + compile_logp_fn_theta(*θ_val)),\n",
    "                               funnel.compile_logp()(test_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddf65c-53d3-4b38-b3ca-30c35d4d47a6",
   "metadata": {},
   "source": [
    "## ∇θ_logLike and ∇θ_logPrior(θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69470930-b7ca-4aa4-9be5-a85e2aeaa381",
   "metadata": {},
   "source": [
    "∇θ_logLike is gradient of θ -> logP(x,z|θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dab433e-086f-4db0-a98b-13776bb7adbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-128.), array(-256.), array(1844.82060635)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_theta_logpt = aesara.grad(\n",
    "    condition_logpt, \n",
    "    wrt=input_theta, \n",
    "    consider_constant=list(set(input_var) - set(input_theta))\n",
    ")\n",
    "compile_grad_theta_fn = aesara.function(input_var, grad_theta_logpt)\n",
    "compile_grad_theta_fn(*z_val, *x_val, *θ_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac4d76-cee5-4d67-8a74-571b8f2879c2",
   "metadata": {},
   "source": [
    "∇θ_logPrior(θ) is gradient of θ -> logPrior(θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c02af32b-0b13-467e-a5a9-80614d57058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-0.), array(1.11022302e-16), array(0.)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_theta_prior = aesara.grad(\n",
    "    theta_logpt, \n",
    "    wrt=input_theta\n",
    ")\n",
    "compile_grad_theta_fn = aesara.function(input_theta, grad_theta_prior)\n",
    "compile_grad_theta_fn(*θ_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92b965-b968-4140-b553-66bf0fbe1120",
   "metadata": {
    "tags": []
   },
   "source": [
    "## zMAP that maximizes the function z -> logP(x,z|θ)\n",
    "\n",
    "We can use [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) to find the MAP.\n",
    "While we have logP(x,z|θ) and gradient of z -> logP(x,z|θ) above, to make using scipy minimize easier we to some additional formatting so that:\n",
    "- `cost_fun` to return a tuple (f, g) containing the objective function and the gradient\n",
    "- Flatten `z` to an 1-D array with shape (n,)\n",
    "\n",
    "Similar logic and API useage see [find_MAP in PyMC](https://github.com/pymc-devs/pymc/blob/1d7130d8cf6e419120e192f8308cf154f4c44074/pymc/tuning/starting.py#L148-L150) and [ValueGradFunction](https://github.com/pymc-devs/pymc/blob/5626a04a1e064ad615e1765e37bcb7ea52887ab7/pymc/model.py#L358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a4e2255-c626-4aec-93fc-596b729df57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ∇z_logLike is gradient of z -> logP(x,z|θ) that will be used in optimization\n",
    "input_z = []\n",
    "input_x_theta = []\n",
    "for var in ordered_input_var:\n",
    "    if var in latent_field:\n",
    "        input_z.append(rv_values[var])\n",
    "    else:\n",
    "        input_x_theta.append(rv_values[var])\n",
    "\n",
    "# Flatten and replace value (similar to ValueGradFunction in pm.Model)\n",
    "flatten_z = at.vector(name='flatten_z')\n",
    "split_point = np.concatenate([np.asarray([0]), np.cumsum([v.size for v in z_val])], axis=-1)\n",
    "z_replace = []\n",
    "for i, np_val in enumerate(z_val):\n",
    "    z_replace.append(at.reshape(flatten_z[split_point[i]:split_point[i+1]], np_val.shape))\n",
    "\n",
    "mapping_fn = aesara.function([flatten_z], z_replace)\n",
    "flatten_z_val = np.concatenate([v.ravel() for v in z_val], axis=-1)\n",
    "# mapping_fn(flatten_z_val)\n",
    "\n",
    "# We minimize the negative loglikelihood\n",
    "condition_logpt_clone = -1.0 * aesara.clone_replace(condition_logpt, dict(zip(input_z, z_replace)))\n",
    "grad_z_clone_tensor = aesara.grad(\n",
    "    condition_logpt_clone,\n",
    "    wrt=flatten_z, \n",
    "    consider_constant=input_x_theta\n",
    ")\n",
    "cost_fun_with_grad = aesara.function(\n",
    "    [flatten_z] + input_x_theta, \n",
    "    [condition_logpt_clone, grad_z_clone_tensor])\n",
    "value_test, grad_test = cost_fun_with_grad(flatten_z_val, *x_val, *θ_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad92c7e9-27fd-493c-aa0c-a63014d213df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some testing\n",
    "grad_z_tensor = aesara.grad(\n",
    "    -condition_logpt,\n",
    "    wrt=input_z, \n",
    "    consider_constant=input_x_theta\n",
    ")\n",
    "\n",
    "output_tensors = [-condition_logpt] + grad_z_tensor\n",
    "cost_fun_with_grad_ = aesara.function(input_var, output_tensors)\n",
    "value_test2, *grad_test2 = cost_fun_with_grad_(*z_val, *x_val, *θ_val)\n",
    "\n",
    "assert value_test == value_test2\n",
    "_ = [np.testing.assert_almost_equal(v1, v2) for v1, v2 in zip(mapping_fn(grad_test), grad_test2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d76a0-b0df-45d2-a4d5-5e83fb95419f",
   "metadata": {},
   "source": [
    "### Using PyMC idioms\n",
    "\n",
    "But either have the exact input -> output signature we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45af9f0b-f152-49f7-b47a-896eeebcdff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rebuild_collect_shared() got an unexpected keyword argument 'strict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_11315/2730642154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_x_theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0;31m out_list, inarray0 = pm.join_nonshared_inputs(\n\u001b[0m\u001b[1;32m     10\u001b[0m     test_point, [-condition_logpt] + grad_z_tensor, input_var, shared)\n\u001b[1;32m     11\u001b[0m \u001b[0mcost_fun_with_grad_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maesaraf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pymc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minarray0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/aesara-dev/lib/python3.9/site-packages/pymc/aesaraf.py\u001b[0m in \u001b[0;36mjoin_nonshared_inputs\u001b[0;34m(point, xs, vars, shared, make_shared)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mreplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mxs_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maesara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxs_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/aesara-dev/lib/python3.9/site-packages/pymc/aesaraf.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mreplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mxs_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maesara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxs_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/aesara-dev/lib/python3.9/site-packages/aesara/graph/basic.py\u001b[0m in \u001b[0;36mclone_replace\u001b[0;34m(output, replace, **rebuild_kwds)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0mtmp_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mnew_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_collect_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrebuild_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;31m# TODO Explain why we call it twice ?!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: rebuild_collect_shared() got an unexpected keyword argument 'strict'"
     ]
    }
   ],
   "source": [
    "test_point['x'] = x_val[0]\n",
    "# shared = pm.make_shared_replacements(test_point, input_z, funnel)\n",
    "shared = {\n",
    "    var: aesara.shared(test_point[var.name],\n",
    "                       var.name + \"_shared\",\n",
    "                       broadcastable=var.broadcastable)\n",
    "    for var in input_x_theta\n",
    "}\n",
    "out_list, inarray0 = pm.join_nonshared_inputs(\n",
    "    test_point, [-condition_logpt] + grad_z_tensor, input_var, shared)\n",
    "cost_fun_with_grad_ = pm.aesaraf.compile_pymc([inarray0], out_list)\n",
    "cost_fun_with_grad_.trust_input = True\n",
    "value_test3, *grad_test3 = cost_fun_with_grad_(flatten_z_val)\n",
    "\n",
    "assert value_test2 == value_test3\n",
    "_ = [np.testing.assert_almost_equal(v1, v2) for v1, v2 in zip(grad_test2, grad_test3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "129fc895-ca95-4669-a023-a6bc7e2cb7fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_test3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_11315/2947228136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalue_test4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_test4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm_val_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mvalue_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue_test3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_test4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value_test3' is not defined"
     ]
    }
   ],
   "source": [
    "extra_vars_and_values = {\n",
    "    var: test_point[var.name]\n",
    "    for var in input_x_theta\n",
    "}\n",
    "pm_val_grad_fn = pm.model.ValueGradFunction([-condition_logpt], input_z, extra_vars_and_values)\n",
    "pm_val_grad_fn.set_extra_values(test_point)\n",
    "value_test4, grad_test4 = pm_val_grad_fn(z_val)\n",
    "\n",
    "assert value_test == value_test3\n",
    "np.testing.assert_almost_equal(grad_test, grad_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915b9ae-1acb-4e86-bb13-407119eeeea3",
   "metadata": {},
   "source": [
    "Once we have the logp fn that also output gradient, optimizing it is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7852857-3b66-44fa-9968-86e287c57afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def zmap_optimization(\n",
    "    cost_fun_with_grad: callable,\n",
    "    initial_z: list,\n",
    "    x: list,\n",
    "    theta: list,\n",
    "    random_init=True,\n",
    "    method='L-BFGS-B',\n",
    "    **kwargs):\n",
    "    x0 = np.concatenate([v.ravel() for v in initial_z], axis=-1)\n",
    "    if random_init:\n",
    "        x0 = np.random.randn(*x0.shape)\n",
    "    return minimize(\n",
    "        cost_fun_with_grad, x0, args=(*x, *theta), method=method, jac=True, **kwargs\n",
    "    )\n",
    "\n",
    "output = zmap_optimization(cost_fun_with_grad, z_val, x_val, θ_val, random_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6ade842-0a17-4013-a878-f596320533ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "zmap_val = mapping_fn(output.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "198b60b2-1151-4e82-b463-4359487c2eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-2.47684961), array(-205.97650422), array(-258.95274151)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_grad_theta_fn = aesara.function(input_var, grad_theta_logpt)\n",
    "compile_grad_theta_fn(*zmap_val, *x_val, *θ_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c3fdc3b-8036-4c22-b9ea-5e74ec64a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n",
      "[array(-97.63759201), array(-231.24619191), array(-450.28506351)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x_sim = sample_x(*θ_val)\n",
    "    output_sim = zmap_optimization(cost_fun_with_grad, z_val, x_sim, θ_val, random_init=False)\n",
    "    zmap_sim = mapping_fn(output_sim.x)\n",
    "    print(compile_grad_theta_fn(*zmap_sim, *x_sim, *θ_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5120b9-54b7-497d-a241-0ed2b4513058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_sim[0][:4], x_val[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74e52143-2e33-4984-8428-0bfa21cfac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.14047278, -0.72145208,  0.31570499,  0.19205645]),\n",
       " array([ 0.5354508 ,  0.43493527,  1.46854744, -0.65141273]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zmap_sim[0][:4], zmap_val[0][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20141d-9dd9-479b-93bb-3f1cea684a92",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "\n",
    "```python\n",
    "θ = # initial guess for θ\n",
    "H = # some guess for Hessian of θ -> logP(θ|x)\n",
    "\n",
    "while norm(θ - θlast) < θtol:\n",
    "    # a bunch of simulated x's generated from P(x,z|θ)\n",
    "    x_sims = [sample_prior_predictive(θ).x for i in 1:nsims] \n",
    "\n",
    "    # zMAP maximizes the function z -> logP(x,z|θ)\n",
    "    zMAP_data = zMAP(x, θ)\n",
    "    zMAP_sims = [zMAP(x_sim, θ) for x_sim in x_sims]\n",
    "\n",
    "    # ∇θ_logLike is gradient of θ -> logP(x,z|θ)\n",
    "    g_data = ∇θ_logLike(zMAP_data, x, θ)\n",
    "    g_sims = [∇θ_logLike(zMAP_sim, x_sim, θ) for (zMAP_sim, x_sim) in zip(zMAP_sims,x_sims)]\n",
    "\n",
    "    # gradient of θ -> logP(θ)\n",
    "    g_prior = ∇θ_logPrior(θ) \n",
    "\n",
    "    θlast = θ\n",
    "    θ -= H \\ (g_data - mean(g_sims) + g_prior)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b861e904-aef7-4d4e-8719-9e5557fad37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flatten_replace_var(values: list, name=''):\n",
    "    flatten_var = at.vector(name='flatten_' + name)\n",
    "    split_point = np.concatenate([np.asarray([0]), \n",
    "                                  np.cumsum([v.size for v in values])],\n",
    "                                 axis=-1)\n",
    "    replace_var = []\n",
    "    for i, np_val in enumerate(values):\n",
    "        replace_var.append(\n",
    "            at.reshape(flatten_var[split_point[i]:split_point[i+1]], np_val.shape))\n",
    "\n",
    "    flatten_var_value = np.concatenate([v.ravel() for v in values], axis=-1)\n",
    "    return replace_var, flatten_var, flatten_var_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86d31725-d037-4d5f-8ed5-e00306e28965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.94064832), array(0.2168093), array(7.97695874)]\n",
      "[array(1.91889214), array(0.21715894), array(2.83067618)]\n",
      "[array(1.84589394), array(0.21729647), array(1.8667429)]\n",
      "[array(1.76505868), array(0.2182955), array(2.05838988)]\n",
      "[array(1.69128104), array(0.21887811), array(1.95125078)]\n",
      "[array(1.62181736), array(0.2196698), array(2.00211943)]\n",
      "[array(1.55707374), array(0.22035834), array(1.97462284)]\n",
      "[array(1.49643699), array(0.22110722), array(1.98900381)]\n",
      "[array(1.43955), array(0.22182981), array(1.98182996)]\n",
      "[array(1.38611779), array(0.22257161), array(1.98657747)]\n",
      "[array(1.33578827), array(0.22330738), array(1.98517197)]\n",
      "[array(1.28832453), array(0.22405029), array(1.98736051)]\n",
      "[array(1.2434521), array(0.22479268), array(1.98774067)]\n",
      "[array(1.20096783), array(0.22553836), array(1.98926245)]\n",
      "[array(1.16066075), array(0.22628482), array(1.9902398)]\n",
      "[array(1.12235896), array(0.22703325), array(1.99159871)]\n",
      "[array(1.08589712), array(0.22778278), array(1.99278468)]\n",
      "[array(1.05113347), array(0.22853378), array(1.99409847)]\n",
      "[array(1.01793586), array(0.22928594), array(1.99534984)]\n",
      "[array(0.98618787), array(0.23003939), array(1.99663751)]\n",
      "[array(0.95578261), array(0.23079401), array(1.99789313)]\n",
      "[array(0.92662444), array(0.23154986), array(1.99914929)]\n",
      "[array(0.898626), array(0.23230692), array(2.00038015)]\n",
      "[array(0.87170837), array(0.2330652), array(2.00159637)]\n",
      "[array(0.84579951), array(0.23382474), array(2.0027877)]\n",
      "[array(0.82083363), array(0.23458558), array(2.00395846)]\n",
      "[array(0.79675036), array(0.23534776), array(2.005105)]\n",
      "[array(0.77349562), array(0.23611127), array(2.00622375)]\n",
      "[array(0.75101928), array(0.23687616), array(2.00731861)]\n",
      "[array(0.72927521), array(0.23764248), array(2.00838658)]\n",
      "[array(0.70822106), array(0.23841026), array(2.00942937)]\n",
      "[array(0.6878178), array(0.23917956), array(2.01044595)]\n",
      "[array(0.66802947), array(0.23995042), array(2.01143729)]\n",
      "[array(0.64882281), array(0.24072287), array(2.01240323)]\n",
      "[array(0.63016706), array(0.24149697), array(2.01334448)]\n",
      "[array(0.6120337), array(0.24227276), array(2.0142613)]\n",
      "[array(0.59439626), array(0.24305029), array(2.01515431)]\n",
      "[array(0.57723015), array(0.2438296), array(2.01602395)]\n",
      "[array(0.56051248), array(0.24461073), array(2.01687083)]\n",
      "[array(0.54422189), array(0.24539372), array(2.01769549)]\n",
      "[array(0.52833846), array(0.24617863), array(2.0184985)]\n",
      "[array(0.5128436), array(0.2469655), array(2.01928042)]\n",
      "[array(0.49771987), array(0.24775435), array(2.02004185)]\n",
      "[array(0.48295098), array(0.24854525), array(2.02078332)]\n",
      "[array(0.4685216), array(0.24933823), array(2.02150542)]\n",
      "[array(0.45441738), array(0.25013333), array(2.02220867)]\n",
      "[array(0.44062481), array(0.25093059), array(2.02289361)]\n",
      "[array(0.42713119), array(0.25173005), array(2.02356078)]\n",
      "[array(0.41392454), array(0.25253175), array(2.02421068)]\n",
      "[array(0.40099358), array(0.25333573), array(2.0248438)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, {'θ0': array(0.40099358), 'θ1': array(0.25333573), 'σ': array(2.0248438)})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from scipy.optimize import OptimizeWarning\n",
    "\n",
    "def MUSE(model: pm.Model, tol=1e-2, nsims=100, \n",
    "         max_iter=50,\n",
    "         minimize_method='L-BFGS-B', \n",
    "         **minimize_kwargs):\n",
    "    if model.potentials:\n",
    "        raise Exception(\"MUSE does not work with model that contains potentials\")\n",
    "        \n",
    "    # Catigorize variables into θ, z, x\n",
    "    model_graph = pm.model_graph.ModelGraph(model)\n",
    "    # θ are priors with no parent\n",
    "    theta = [var for var in model.basic_RVs if model_graph.get_parent_names(var) == set()]\n",
    "    # The remaining free variables are z\n",
    "    z = [var for var in model.free_RVs if var not in theta]\n",
    "    x: list = model.observed_RVs\n",
    "\n",
    "    # Compute logp and gradient\n",
    "    # For each node in the model, get the correspondent variable for computing logp\n",
    "    rv_values = {}\n",
    "    for var in z + x + theta:\n",
    "        if var in x:\n",
    "            value_var = var.type()\n",
    "            value_var.name = var.name\n",
    "        else:\n",
    "            value_var = model.rvs_to_values[var]\n",
    "        rv_values[var] = value_var\n",
    "\n",
    "    rv_logps = joint_logpt(list(rv_values.keys()), rv_values, sum=False, jacobian=True)\n",
    "    logpt_nodes = {}\n",
    "    for k, logp in zip(rv_values.keys(), rv_logps):\n",
    "        node_logp = logp.sum()\n",
    "        node_logp.name = k.name + \"_logpt\"\n",
    "        logpt_nodes[k] = node_logp\n",
    "\n",
    "    # A dict containing array so we can use to infer shape \n",
    "    test_point = model.initial_point()\n",
    "    # θ, z, x in unbounded space (variable that actually used for computing logp)\n",
    "    # and their test value\n",
    "    input_theta = [rv_values[v] for v in theta]\n",
    "    theta_val = [test_point[rv_values[v].name] for v in theta]\n",
    "    input_z = [rv_values[v] for v in z]\n",
    "    z_val = [test_point[rv_values[v].name] for v in z]\n",
    "    input_x = [rv_values[v] for v in x]\n",
    "    x_val = [model.rvs_to_values[v].data for v in x]\n",
    "    \n",
    "    # Flatten and concat θ into 1D tensors\n",
    "    (replace_theta,\n",
    "     flatten_theta,\n",
    "     init_theta,\n",
    "     ) = create_flatten_replace_var(theta_val, name='theta')\n",
    "    # Replace theta in original space\n",
    "    replace_theta_org = {}\n",
    "    for org_var, input_var, replace_var in zip(theta, input_theta, replace_theta):\n",
    "        if hasattr(input_var.tag, \"transform\"):\n",
    "            replace_theta_org[org_var] = input_var.tag.transform.backward(\n",
    "                replace_var, *org_var.owner.inputs)\n",
    "        else:\n",
    "            replace_theta_org[org_var] = replace_var\n",
    "    # Function to sample x conditioned on θ\n",
    "    x_clone = aesara.clone_replace(x, replace_theta_org)\n",
    "    sample_x: callable = aesara.function([flatten_theta], x_clone)\n",
    "    mapping_theta_fn = aesara.function([flatten_theta], list(replace_theta_org.values()))\n",
    "    # _ = sample_x(init_theta)\n",
    "\n",
    "    # Flatten z into 1D tensor\n",
    "    (replace_z,\n",
    "     flatten_z,\n",
    "     init_z,\n",
    "     ) = create_flatten_replace_var(z_val, name='z')\n",
    "\n",
    "    # Prepare function for MAP estimate of z\n",
    "    # logP(x,z|θ)\n",
    "    condition_logpt = at.sum([logpt_nodes[var] for var in x + z])\n",
    "    condition_logpt_clone = aesara.clone_replace(\n",
    "        condition_logpt, dict(zip(input_z + input_theta,\n",
    "                                  replace_z + replace_theta)))\n",
    "    \n",
    "    # We minimize the negative loglikelihood\n",
    "    neg_condition_logpt = -1.0 * condition_logpt_clone\n",
    "    grad_z_clone_tensor = aesara.grad(\n",
    "        neg_condition_logpt,\n",
    "        wrt=flatten_z, \n",
    "        consider_constant=input_x + input_theta\n",
    "    )\n",
    "    cost_fun_with_grad = aesara.function(\n",
    "        [flatten_z] + input_x + [flatten_theta], \n",
    "        [neg_condition_logpt, grad_z_clone_tensor])\n",
    "\n",
    "    # gradient of θ -> logP(x,z|θ)\n",
    "    grad_theta_clone_tensor = aesara.grad(\n",
    "        condition_logpt_clone,\n",
    "        wrt=flatten_theta, \n",
    "        consider_constant=input_x + input_z\n",
    "    )\n",
    "    compile_grad_theta_fn = aesara.function(\n",
    "        [flatten_z] + input_x + [flatten_theta],\n",
    "        grad_theta_clone_tensor)\n",
    "    \n",
    "    # # testing\n",
    "    # grad_test = aesara.grad(condition_logpt, wrt=input_theta, consider_constant=input_x + input_z)\n",
    "    # test_fn = aesara.function(input_z + input_x + input_theta, grad_test)\n",
    "    # map_fn_z = aesara.function([flatten_z], replace_z)\n",
    "    # map_fn_θ = aesara.function([flatten_theta], replace_theta)\n",
    "    # test_z = np.random.randn(*init_z.shape)\n",
    "    # test_θ = np.random.randn(*init_theta.shape)\n",
    "    # return compile_grad_theta_fn(test_z, *x_val, test_θ), test_fn(*map_fn_z(test_z), *x_val, *map_fn_θ(test_θ))\n",
    "    \n",
    "    # gradient of θ -> logP(θ)\n",
    "    theta_logpt = at.sum([logpt_nodes[var] for var in theta])\n",
    "    theta_logpt_clone = aesara.clone_replace(\n",
    "        theta_logpt, dict(zip(input_theta, replace_theta)))\n",
    "    grad_theta_prior = aesara.grad(\n",
    "        theta_logpt_clone, \n",
    "        wrt=flatten_theta\n",
    "    )\n",
    "    compile_grad_theta_prior_fn = aesara.function([flatten_theta], grad_theta_prior)\n",
    "    \n",
    "    # testing\n",
    "    # grad_test = aesara.grad(theta_logpt, wrt=input_theta)\n",
    "    # test_fn = aesara.function(input_theta, grad_test)\n",
    "    # return compile_grad_theta_prior_fn(init_theta), test_fn(*theta_val)\n",
    "\n",
    "    # MUSE algorithm\n",
    "    theta_est = np.random.randn(*init_theta.shape)\n",
    "    last_theta = np.random.randn(*init_theta.shape)\n",
    "    H = - np.eye(len(init_theta)) * 500.\n",
    "    i = 0\n",
    "    while (np.linalg.norm(theta_est - last_theta) > tol) & (i < max_iter):\n",
    "        i += 1\n",
    "        output = minimize(\n",
    "            cost_fun_with_grad, init_z, args=(*x_val, theta_est), \n",
    "            method=minimize_method, jac=True, **minimize_kwargs\n",
    "        )\n",
    "        if not output.success:\n",
    "            warnings.warn(\"zMAP did not converge.\", OptimizeWarning)\n",
    "        zMAP_data = output.x\n",
    "        g_data = compile_grad_theta_fn(zMAP_data, *x_val, theta_est)\n",
    "        g_prior = compile_grad_theta_prior_fn(theta_est)\n",
    "        \n",
    "        g_sims = np.zeros([nsims, *g_data.shape], dtype=g_data.dtype)\n",
    "        for j in range(nsims):\n",
    "            x_sim = sample_x(theta_est)\n",
    "            output_sim = minimize(\n",
    "                cost_fun_with_grad, init_z, args=(*x_sim, theta_est), \n",
    "                method=minimize_method, jac=True, **minimize_kwargs\n",
    "            )\n",
    "            zMAP_sim = output_sim.x\n",
    "            g_sim = compile_grad_theta_fn(zMAP_sim, *x_sim, theta_est)\n",
    "            g_sims[j] = g_sim\n",
    "\n",
    "        expect_g_sim = np.mean(g_sims, axis=0)\n",
    "        last_theta = theta_est\n",
    "        theta_est = theta_est - np.linalg.solve(H, (g_data - expect_g_sim + g_prior))\n",
    "        print(mapping_theta_fn(theta_est))\n",
    "\n",
    "    return i, {\n",
    "        org_var.name: est \n",
    "        for org_var, est in zip(\n",
    "            replace_theta_org.keys(),\n",
    "            mapping_theta_fn(theta_est))\n",
    "    }\n",
    "\n",
    "MUSE(funnel, nsims=100, tol=1e-5, max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc22b07-7599-42ea-a43e-4693540b3159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "048912e989d3122349b72d4b377d6cfb3d6510252a82dfc6720674d87d4b18a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('aesara-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
